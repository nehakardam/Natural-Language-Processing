{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module \n",
    "import os \n",
    "\n",
    "# Folder Path \n",
    "path = r'/Users/nehakardam/Documents/UWclasses /CSE NLP/A1/A1_data/review_polarity/txt_sentoken/pos'\n",
    "\n",
    "# Change the directory \n",
    "os.chdir(path) \n",
    "\n",
    "# Read text File \n",
    "def read_text_file(file_path): \n",
    "    with open(file_path, 'r') as f: \n",
    "        return f.read().splitlines()  \n",
    "\n",
    "# iterate through all file \n",
    "collection_of_data_pos = []\n",
    "for file in os.listdir(): \n",
    "    # Check whether file is in text format or not \n",
    "    if file.endswith(\".txt\"): \n",
    "        file_path = f\"{path}/{file}\"\n",
    "        # call read text file function \n",
    "        collection_of_data_pos = collection_of_data_pos + read_text_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.DataFrame(collection_of_data_pos, columns = ['review'])\n",
    "df_pos['sentiment'] = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Path \n",
    "path = r'/Users/nehakardam/Documents/UWclasses /CSE NLP/A1/A1_data/review_polarity/txt_sentoken/neg'\n",
    "\n",
    "# Change the directory \n",
    "os.chdir(path)   \n",
    "\n",
    "# iterate through all file \n",
    "collection_of_data_neg = []\n",
    "for file in os.listdir(): \n",
    "    # Check whether file is in text format or not \n",
    "    if file.endswith(\".txt\"): \n",
    "        file_path = f\"{path}/{file}\"\n",
    "        # call read text file function \n",
    "        collection_of_data_neg = collection_of_data_neg + read_text_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = pd.DataFrame(collection_of_data_neg, columns = ['review'])\n",
    "df_neg['sentiment'] = 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the coens also add plenty of quirky touches th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the only exception is rob schneider , who is a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from the bumbling jar jar , to a one-man , two...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( note : there are spoilers regarding the fil...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seven years ago , his first book was a hit .</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>the characters just wander around the city aim...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>wait a minute \" .</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>she's great to look at , and she can certainly...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>mcconaughey is then drafted in as his lawyer ,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>mulan's crippled father is called , but mulan ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      the coens also add plenty of quirky touches th...  positive\n",
       "1      the only exception is rob schneider , who is a...  negative\n",
       "2      from the bumbling jar jar , to a one-man , two...  positive\n",
       "3       ( note : there are spoilers regarding the fil...  positive\n",
       "4          seven years ago , his first book was a hit .   positive\n",
       "...                                                  ...       ...\n",
       "64715  the characters just wander around the city aim...  negative\n",
       "64716                                 wait a minute \" .   negative\n",
       "64717  she's great to look at , and she can certainly...  positive\n",
       "64718  mcconaughey is then drafted in as his lawyer ,...  negative\n",
       "64719  mulan's crippled father is called , but mulan ...  positive\n",
       "\n",
       "[64720 rows x 2 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#both the dataframe of positive and negative reviews are concatinated to one dataframe named 'collection_of_data'\n",
    "df_pos_neg = [df_pos, df_neg]\n",
    "Collection_of_data = pd.concat(df_pos_neg)\n",
    "#Shuffle the columns of the data\n",
    "movie_reviews= Collection_of_data.sample(frac=1).reset_index(drop=True)\n",
    "movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='sentiment', data=movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(movie_reviews['review'])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = movie_reviews['sentiment']\n",
    "\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) \n",
    "\n",
    "# 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12944"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val= tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38832"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_val=pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2570,    5, 3228,    4, 1601,  144, 1493,    7, 3007,   17,    1,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0], dtype=int32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('/Users/nehakardam/Documents/UWclasses /CSE NLP/A4/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:])\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32331"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32331"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 100, 100)          3233100   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 10001     \n",
      "=================================================================\n",
      "Total params: 3,243,101\n",
      "Trainable params: 10,001\n",
      "Non-trainable params: 3,233,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "304/304 [==============================] - 1s 2ms/step - loss: 0.6854 - acc: 0.5638\n",
      "Epoch 2/6\n",
      "304/304 [==============================] - 1s 2ms/step - loss: 0.6579 - acc: 0.6058\n",
      "Epoch 3/6\n",
      "304/304 [==============================] - 1s 3ms/step - loss: 0.6472 - acc: 0.6204\n",
      "Epoch 4/6\n",
      "304/304 [==============================] - 1s 2ms/step - loss: 0.6397 - acc: 0.6284\n",
      "Epoch 5/6\n",
      "304/304 [==============================] - 1s 3ms/step - loss: 0.6342 - acc: 0.6357\n",
      "Epoch 6/6\n",
      "304/304 [==============================] - 1s 3ms/step - loss: 0.6311 - acc: 0.6370\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6867 - acc: 0.5864\n",
      "Epoch 2/6\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6538 - acc: 0.6170\n",
      "Epoch 3/6\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6355 - acc: 0.6342\n",
      "Epoch 4/6\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6245 - acc: 0.6465\n",
      "Epoch 5/6\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6112 - acc: 0.6592\n",
      "Epoch 6/6\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6041 - acc: 0.6692\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_val, y_val, batch_size=128, epochs=6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 0s 700us/step - loss: 0.6953 - acc: 0.5826\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.714830756187439\n",
      "Test Accuracy: 0.6141068935394287\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "model = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 100, 100)          3233100   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 96, 128)           64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,297,357\n",
      "Trainable params: 64,257\n",
      "Non-trainable params: 3,233,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "304/304 [==============================] - 9s 29ms/step - loss: 0.6719 - acc: 0.5866\n",
      "Epoch 2/6\n",
      "304/304 [==============================] - 9s 31ms/step - loss: 0.6227 - acc: 0.6546\n",
      "Epoch 3/6\n",
      "304/304 [==============================] - 10s 33ms/step - loss: 0.5876 - acc: 0.6918\n",
      "Epoch 4/6\n",
      "304/304 [==============================] - 9s 31ms/step - loss: 0.5519 - acc: 0.7213\n",
      "Epoch 5/6\n",
      "304/304 [==============================] - 7s 22ms/step - loss: 0.5069 - acc: 0.7613\n",
      "Epoch 6/6\n",
      "304/304 [==============================] - 7s 21ms/step - loss: 0.4673 - acc: 0.7871\n"
     ]
    }
   ],
   "source": [
    "history_1 = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.6817 - acc: 0.6148\n",
      "Epoch 2/6\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.5544 - acc: 0.7184\n",
      "Epoch 3/6\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.4957 - acc: 0.7685\n",
      "Epoch 4/6\n",
      "102/102 [==============================] - 2s 21ms/step - loss: 0.4436 - acc: 0.8123\n",
      "Epoch 5/6\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.4061 - acc: 0.8422\n",
      "Epoch 6/6\n",
      "102/102 [==============================] - 2s 22ms/step - loss: 0.3575 - acc: 0.8816\n"
     ]
    }
   ],
   "source": [
    "history_2 = model.fit(X_val, y_val, batch_size=128, epochs=6, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 1s 2ms/step - loss: 0.7148 - acc: 0.6141\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.714830756187439\n",
      "Test Accuracy: 0.6141068935394287\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.535704493522644"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6926972270011902"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.65      6286\n",
      "           1       0.00      0.00      0.00      6658\n",
      "\n",
      "    accuracy                           0.49     12944\n",
      "   macro avg       0.24      0.50      0.33     12944\n",
      "weighted avg       0.24      0.49      0.32     12944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fine Tuning Example, classification VGG16 with CIFAR 10, we import the necessary libraries\n",
    "import tensorflow as tf\n",
    "from keras import callbacks\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Instantiate an optimizer.\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.optimizers' has no attribute 'SGD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-325-0e295f5bbd79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.optimizers' has no attribute 'SGD'"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=['acc',f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9),metrics=[\"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
